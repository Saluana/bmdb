/**
 * Simple Debug Script for Storage Comparison
 * Tests MemoryStorage vs BinaryStorage with bulk inserts
 */

import { Table, MemoryStorage, BinaryStorage } from './dist/index.js';

interface TestUser {
    id?: number;
    name: string;
    email: string;
    department: string;
    salary: number;
}

function generateUsers(count: number): TestUser[] {
    const departments = ['Engineering', 'Sales', 'Marketing', 'HR', 'Finance'];
    const users: TestUser[] = [];

    for (let i = 0; i < count; i++) {
        users.push({
            name: `User ${i}`,
            email: `user${i}@company.com`,
            department: departments[i % departments.length],
            salary: 50000 + (i % 100000),
        });
    }

    return users;
}

async function testMemoryStorage() {
    console.log('\nğŸ§ª Testing MemoryStorage (Performance Optimized)');
    console.log('================================================');

    const storage = new MemoryStorage();
    const table = new Table<TestUser>(storage, 'test_table');

    try {
        // Test small dataset
        console.log('ğŸ“Š Small dataset (1,000 users)...');
        const smallUsers = generateUsers(1000);

        let start = performance.now();
        const smallIds = table.insertMultiple(smallUsers);
        let duration = performance.now() - start;

        console.log(
            `âœ… Inserted ${smallIds.length} users in ${duration.toFixed(2)}ms`
        );
        console.log(
            `ğŸ“ˆ Rate: ${((smallIds.length / duration) * 1000).toFixed(
                0
            )} users/second`
        );

        // Test large dataset
        console.log('\nğŸ“Š Large dataset (25,000 users)...');
        table.truncate();
        const largeUsers = generateUsers(25000);

        start = performance.now();
        const largeIds = table.insertMultiple(largeUsers);
        duration = performance.now() - start;

        console.log(
            `âœ… Inserted ${largeIds.length} users in ${duration.toFixed(2)}ms`
        );
        console.log(
            `ğŸ“ˆ Rate: ${((largeIds.length / duration) * 1000).toFixed(
                0
            )} users/second`
        );

        return true;
    } catch (error) {
        console.error('âŒ MemoryStorage test failed:', error);
        return false;
    }
}

async function testBinaryStorage() {
    console.log('\nğŸ§ª Testing BinaryStorage (B-tree Implementation)');
    console.log('================================================');

    try {
        const storage = new BinaryStorage('debug-test.bmdb');
        const table = new Table<TestUser>(storage, 'test_table');

        // Test very small dataset first
        console.log('ğŸ“Š Very small dataset (100 users)...');
        const verySmallUsers = generateUsers(100);

        let start = performance.now();
        const verySmallIds = table.insertMultiple(verySmallUsers);
        let duration = performance.now() - start;

        console.log(
            `âœ… Inserted ${verySmallIds.length} users in ${duration.toFixed(
                2
            )}ms`
        );

        // Test small dataset
        console.log('\nğŸ“Š Small dataset (1,000 users)...');
        table.truncate();
        const smallUsers = generateUsers(1000);

        start = performance.now();
        const smallIds = table.insertMultiple(smallUsers);
        duration = performance.now() - start;

        console.log(
            `âœ… Inserted ${smallIds.length} users in ${duration.toFixed(2)}ms`
        );
        console.log(
            `ğŸ“ˆ Rate: ${((smallIds.length / duration) * 1000).toFixed(
                0
            )} users/second`
        );

        // Test progressively larger datasets to find breaking point
        const testSizes = [2000, 5000, 10000];

        for (const size of testSizes) {
            console.log(`\nğŸ“Š Testing ${size.toLocaleString()} users...`);
            table.truncate();
            const users = generateUsers(size);

            try {
                start = performance.now();
                const ids = table.insertMultiple(users);
                duration = performance.now() - start;

                console.log(
                    `âœ… Inserted ${ids.length} users in ${duration.toFixed(
                        2
                    )}ms`
                );
                console.log(
                    `ğŸ“ˆ Rate: ${((ids.length / duration) * 1000).toFixed(
                        0
                    )} users/second`
                );
            } catch (error) {
                console.error(
                    `âŒ BinaryStorage failed at ${size} users:`,
                    error
                );
                if (
                    error.message &&
                    error.message.includes('Failed to find leaf node')
                ) {
                    console.log('ğŸ” This is the B-tree corruption issue!');
                }
                break;
            }
        }

        storage.close();
        return true;
    } catch (error) {
        console.error('âŒ BinaryStorage test failed:', error);
        return false;
    }
}

async function main() {
    console.log('ğŸš€ Storage Performance & Stability Test');
    console.log('=======================================');

    const memorySuccess = await testMemoryStorage();
    const binarySuccess = await testBinaryStorage();

    console.log('\nğŸ“Š Test Summary:');
    console.log('================');
    console.log(`MemoryStorage: ${memorySuccess ? 'âœ… PASS' : 'âŒ FAIL'}`);
    console.log(`BinaryStorage: ${binarySuccess ? 'âœ… PASS' : 'âŒ FAIL'}`);

    if (memorySuccess && !binarySuccess) {
        console.log(
            '\nğŸ” Analysis: MemoryStorage works fine with performance optimizations.'
        );
        console.log(
            '    BinaryStorage has a B-tree corruption issue at scale.'
        );
        console.log(
            '    The hanging issue in tests was likely related to BinaryStorage, not MemoryStorage.'
        );
    }
}

if (import.meta.main) {
    main().catch(console.error);
}
